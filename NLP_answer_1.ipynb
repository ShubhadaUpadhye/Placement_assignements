{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##NLP answer_1\n",
    "from googleapiclient.discovery import build\n",
    "import requests\n",
    "from urllib.request import urlopen as urReq\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import html\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "stop_words=stopwords.words(\"english\")\n",
    "\n",
    "api_key='AIzaSyB7og-sgYVOcVbnnqZ4xpWhibsSR3F82gQ'\n",
    "channel_id='UCNU_lfiiWBdtULKOw6X0Dig'\n",
    "youtube=build('youtube','v3',developerKey=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##fetching comments form youtube channel###\n",
    "comment_list=[]\n",
    "\n",
    "##video_url of the video from which comments will be fetched##\n",
    "video_url=\"https://www.youtube.com/watch?v=XgWqumlu76U\"\n",
    "\n",
    "def comment_thread(video_id):\n",
    "        try:\n",
    "            request = youtube.commentThreads().list(part=\"replies,snippet\",videoId=video_id,maxResults=100)\n",
    "            response = request.execute()\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        else:\n",
    "            return response\n",
    "comment_result=comment_thread(video_id='XgWqumlu76U')\n",
    "comment_details =comment_result['items']\n",
    "for i in range(len(comment_details)):\n",
    "    try:\n",
    "        comments=comment_details[i]['snippet']['topLevelComment']['snippet']['textDisplay']\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    else:\n",
    "        comment_list.append(comments)\n",
    "\n",
    "comment_dict={'comments':comment_list}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##saving fetched comments in csv format####\n",
    "df=pd.DataFrame(comment_dict)\n",
    "df.to_csv('comments.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######extracting text from comments#########\n",
    "\n",
    "def comment_text(text):\n",
    "    lem_words = []\n",
    "    new_list=[]\n",
    "\n",
    "    try:\n",
    "        ##changing text to lower_case##\n",
    "        text=text.lower()\n",
    "        ##removing tabs if any###\n",
    "        text=text.expandtabs(0)\n",
    "        ####removing punctuations\n",
    "        text=text.translate(str.maketrans('', '', string.punctuation))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    else:\n",
    "        ####splitting words of phrase/para\n",
    "        token_words = nltk.word_tokenize(text)\n",
    "        #print(token_words)\n",
    "        \n",
    "    def remove_stop_words(token_words):\n",
    "        for words in token_words:\n",
    "            if words not in stop_words:\n",
    "                new_list.append(words)\n",
    "    remove_stop_words(token_words)\n",
    "    \n",
    "    def lemmatize_words(words_list):\n",
    "        lm= WordNetLemmatizer()\n",
    "        for word in words_list:\n",
    "            lem_words.append(lm.lemmatize(word))\n",
    "    lemmatize_words(new_list)\n",
    "    #print(lem_words)\n",
    "    \n",
    "for i in comment_list:\n",
    "    soup=bs(i,'html.parser').text\n",
    "    comments=html.unescape(soup)\n",
    "    comment_text(comments)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

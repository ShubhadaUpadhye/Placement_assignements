{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##NLP answer_1\n",
    "from googleapiclient.discovery import build\n",
    "import requests\n",
    "from urllib.request import urlopen as urReq\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import html\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "stop_words=stopwords.words(\"english\")\n",
    "\n",
    "api_key='AIzaSyB7og-sgYVOcVbnnqZ4xpWhibsSR3F82gQ'\n",
    "channel_id='UCNU_lfiiWBdtULKOw6X0Dig'\n",
    "youtube=build('youtube','v3',developerKey=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##fetching comments###\n",
    "comment_list=[]\n",
    "\n",
    "video_url=\"https://www.youtube.com/watch?v=XgWqumlu76U\"\n",
    "\n",
    "def comment_thread(video_id):\n",
    "        try:\n",
    "            request = youtube.commentThreads().list(part=\"replies,snippet\",videoId=video_id,maxResults=100)\n",
    "            response = request.execute()\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        else:\n",
    "            return response\n",
    "comment_result=comment_thread(video_id='XgWqumlu76U')\n",
    "comment_details =comment_result['items']\n",
    "for i in range(len(comment_details)):\n",
    "    try:\n",
    "        comments=comment_details[i]['snippet']['topLevelComment']['snippet']['textDisplay']\n",
    "        comments=html.unescape(comments)\n",
    "        comments=bs(comments,'html.parser').text\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    else:\n",
    "        comment_list.append(comments)\n",
    "\n",
    "comment_dict={'comments':comment_list}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "##saving fetched comments in csv format####\n",
    "df=pd.DataFrame(comment_dict)\n",
    "df.to_csv('comments.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dont', 'forget', 'to', 'subscribe', 'krish', 'naik', 'hindi', 'to', 'learn', 'data', 'science', 'in', 'hindi', 'httpswwwyoutubecomkrishnaikhindi']\n",
      "['krish', 'bhai', 'can', 'you', 'please', 'suggest', 'the', 'playlist', 'of', 'your', 'channel', 'where', 'i', 'can', 'have', 'detailed', 'lectures', 'to', 'machine', 'learning', 'i', 'have', 'learnt', 'from', 'these', '5', 'videos', 'now', 'i', 'need', 'more', 'to', 'boost', 'up', 'my', 'basics', 'and', 'start', 'python']\n",
      "['i', 'have', 'a', 'question', 'is', 'their', 'any', 'project', 'or', 'ml', 'algorthim', 'or', 'model', 'which', 'convert', 'sentence', 'data', 'into', 'specific', 'image', 'we', 'are', 'working', 'on', 'sign', 'language', 'project', 'but', 'we', 'are', 'stuck', 'we', 'want', 'to', 'convert', 'certain', 'sentence', 'like', 'hindi', 'language', 'to', 'sign', 'images', 'please', 'provide', 'some', 'tips']\n",
      "['hello', 'sir', 'etl', 'development', 'is', 'part', 'of', 'datascience', 'so', 'we', 'need', 'to', 'learn', 'that', 'as', 'well']\n",
      "['hi', 'krish', 'for', 'point5', 'for', 'model', 'based', 'learning', 'ideally', 'the', 'training', 'input', 'data', 'can', 'be', 'thrown', 'away', 'after', 'model', 'training', 'however', 'if', 'we', 'talk', 'of', 'real', 'world', 'use', 'case', 'the', 'data', 'should', 'be', 'preserved', 'right', 'for', 'reproducing', 'in', 'some', 'scenarios', 'for', 'eg', 'if', 'the', 'currently', 'deployed', 'model', 'is', 'overfitting', 'having', 'the', 'trained', 'data', 'might', 'be', 'helpful', 'in', 'knowing', 'what', 'caused', 'it', 'to', 'happenwould', 'like', 'to', 'know', 'your', 'thoughts', 'on', 'this']\n",
      "['next', 'video']\n",
      "['so', 'the', 'upper', 'curved', 'formation', 'of', 'data', 'between', '2', 'points', 'can', 'be', 'formed', 'through', 'logx', 'similarly', 'the', 'downward', 'curve', 'can', 'be', 'formed', 'through', 'exponential', 'e', 'to', 'the', 'power', 'of', 'x', 'the', 'straight', 'line', 'as', 'linear', 'y', 'mxc', 'where', 'c', '0', 'since', 'we', 'are', 'only', 'looking', 'for', 'the', 'ideal', 'pattern', 'and', 'then', 'there', 'is', 'polynomial', 'of', '2degree', 'order', 'x2', 'or', 'n', 'degrees', 'xn', 'on', 'the', 'other', 'hand', 'the', 'joining', 'to', '2', 'dots', 'has', 'n', 'number', 'of', 'ways']\n",
      "['hello', 'sir', 'i', 'am', 'going', 'to', 'apply', 'for', 'junior', 'data', 'scientist', 'position', 'so', 'by', 'reading', 'the', 'description', 'can', 'you', 'suggest', 'me', 'what', 'sorts', 'of', 'project', 'should', 'i', 'need', 'to', 'do']\n",
      "['hello', 'sir', 'please', 'reduce', 'the', 'course', 'for', 'one', 'neuron', 'or', 'please', 'give', 'more', 'year', 'validity', 'in', 'one', 'neuron', 'when', 'we', 'pay', '25000', 'for', 'one', 'neuron', 'then', 'the', 'validity', 'of', '2', 'year', 'is', 'not', 'worth', 'for', 'money', 'please', 'help', 'sir']\n",
      "['sir', 'so', 'if', 'we', 'want', 'to', 'create', 'a', 'mini', 'drone', 'which', 'is', 'powered', 'with', 'ai', 'then', 'what', 'technologies', 'we', 'have', 'to', 'use', 'like', 'machine', 'learning', 'deep', 'learning', 'etc', 'and', 'if', 'we', 'have', 'to', 'use', 'more', 'then', '1', 'technology', 'then', 'what', 'will', 'be', 'the', 'order']\n",
      "['sir', 'next', 'video', 'kab', 'ayegiðŸ˜¢']\n",
      "['waiting', 'for', 'next', 'video']\n",
      "['krish']\n",
      "['hi', 'krish', 'i', 'just', 'got', 'to', 'the', 'channel', 'few', 'days', 'ago', 'and', 'trust', 'me', 'this', 'is', 'the', 'best', 'course', 'available', 'on', 'ai', 'i', 'am', 'a', 'indian', 'student', 'doing', 'masters', 'in', 'artificial', 'intelligence', 'from', 'the', 'university', 'of', 'milan', 'italy', 'but', 'i', 'must', 'say', 'ur', 'explanation', 'is', 'far', 'better', 'than', 'the', 'italian', 'professors', 'please', 'keep', 'up', 'the', 'good', 'work', 'bro']\n",
      "['use', 'a', 'sigmoid', 'function', 'to', 'generate', 'a', 'set', 'of', 'point', 'above', 'the', 'std', 'linear', 'points']\n",
      "['sir', 'bcom', 'waale', 'data', 'science', 'mien', 'jaa', 'sakte', 'hein', 'kya']\n",
      "['may', 'be', 'we', 'can', 'use', 'linspace', 'command', 'to', 'generate', 'linearly', 'spaced', 'points', 'between', 'the', 'given', 'range']\n",
      "['hi', 'krish', 'recently', 'you', 'created', 'video', 'based', 'on', 'a', 'ec2', 'instance', 'its', 'very', 'useful', 'but', 'please', 'create', 'a', 'video', 'in', 'mlops', 'with', 'sagemaker']\n",
      "['can', 'you', 'pls', 'share', 'practical', 'use', 'cases', 'for', 'instance', 'based', 'learning', 'what', 'are', 'the', 'pros', 'of', 'instance', 'based', 'learning', 'no', 'training', 'time', 'needed']\n",
      "['hey', 'krishenjoying', 'your', 'session', 'a', 'lotcan', 'you', 'tell', 'the', 'estimate', 'days', 'to', 'complete', 'this', 'entire', 'course']\n",
      "['thank', 'you', 'for', 'this', 'awesome', 'course', 'krish', 'i', 'have', 'been', 'following', 'your', 'videos', 'for', 'long', 'time', 'now', 'is', 'there', 'any', 'prerequisite', 'to', 'this', 'course']\n",
      "['thank', 'you']\n",
      "['sir', 'could', 'you', 'please', 'add', 'model', 'building', 'and', 'deployment', 'of', 'house', 'price', 'prediction', 'using', 'advanced', 'regression', 'techniques', 'project', 'in', 'the', 'playlist', 'and', 'converting', 'into', 'streamlit', 'app']\n",
      "['thanks']\n",
      "['hi', 'krish', 'siramazing', 'video', 'as', 'always', 'thank', 'youto', 'create', 'a', 'dataset', 'from', 'scratch', 'we', 'can', 'use', 'from', 'sklearndatasets', 'import', 'makeregression', 'and', 'if', 'the', 'points', 'are', 'given', 'then', 'as', 'maroju', 'mentioned', 'equation', 'of', 'line', 'will', 'do', 'is', 'it']\n",
      "['i', 'love', 'how', 'you', 'start', 'the', 'video', 'with', 'the', 'question', 'but', 'the', 'answer', 'to', 'the', 'question', 'is']\n",
      "['do', 'instance', 'based', 'learning', 'and', 'model', 'based', 'learning', 'work', 'like', 'supervisedunsupervised', 'ml', 'how', 'do', 'you', 'really', 'make', 'a', 'difference', 'while', 'working', 'with', 'real', 'data']\n",
      "['def', 'lineareqnpoint1', 'point2', 'newpt', 'x1', 'x2', 'point1', 'y1', 'y2', 'point2', 'slope', 'y2y1x2x1', 'b', 'y1slope', 'x1', 'newy', 'slope', 'newpt', 'b', 'return', 'newpt', 'newy', 'give', 'feedback', 'please', 'if', 'it', 'is', 'right']\n",
      "['please', 'used', 'to', 'share', 'this', 'notepad', 'notes', 'also', 'sir']\n",
      "['first', 'we', 'observe', 'both', 'data', 'points', 'that', 'what', 'is', 'relation', 'of', 'their', 'x', 'coordinate', 'with', 'y', 'coordinate', 'if', 'it', 'is', 'linear', 'then', 'we', 'use', 'linear', 'line', 'else', 'if', 'there', 'is', 'any', 'polynomial', 'relation', 'we', 'should', 'go', 'with', 'polynomial', 'degree']\n",
      "['thank', 'you', 'krishbhai']\n",
      "['great', 'video', 'sir']\n",
      "['whats', 'the', 'right', 'answer']\n",
      "['adding', 'of', 'slope', 'intercept', 'linear']\n",
      "['hello', 'sir', 'can', 'u', 'tell', 'us', 'which', 'algorithm', 'are', 'instance', 'based', 'and', 'which', 'are', 'model', 'based', 'learning', 'by', 'some', 'practical', 'implications']\n",
      "['hi', 'krishfantastic', 'vide', 'againit', 'will', 'be', 'great', 'if', 'you', 'could', 'share', 'the', 'notespresentation', 'you', 'make', 'during', 'the', 'videos']\n",
      "['to', 'generate', 'linear', 'points', 'between', 'those', 'two', 'points', 'we', 'can', 'use', 'equation', 'of', 'straight', 'line', 'ie', 'ymxchere', 'to', 'calculate', 'slope', 'we', 'have', 'formula', 'm', 'y2y1x2x1we', 'can', 'put', 'in', 'some', 'x', 'value', 'to', 'calculate', 'ypoint', 'where', 'line', 'touches', 'y', 'axisnow', 'we', 'can', 'plug', 'in', 'any', 'values', 'ranging', 'between', 'x1', 'and', 'x2', 'in', 'the', 'equation', 'to', 'get', 'ycoordinatesfor', 'polynomial', 'points', 'same', 'to', 'follow', 'using', 'quadratic', 'polynomial', 'equationto', 'generate', 'equally', 'spaced', 'points', 'we', 'can', 'use', 'linspace', 'function', 'in', 'numpy']\n",
      "['can', 'you', 'provide', 'examples', 'for', 'model', 'based', 'training', 'system', 'and', 'for', 'instance', 'based', 'training', 'you', 'only', 'gave', 'knn', 'what', 'are', 'other', 'examples', 'thanks', 'in', 'advance']\n",
      "['great', 'video', 'as', 'usualive', 'been', 'looking', 'at', 'many', 'of', 'your', 'content', 'here', 'on', 'youtube', 'they', 'are', 'really', 'helpfuli', 'have', 'a', 'question', 'unrelated', 'to', 'the', 'content', 'itself', 'what', 'do', 'you', 'use', 'to', 'create', 'the', 'writing', 'on', 'videos', 'like', 'these', 'the', 'hardware', 'and', 'also', 'the', 'appssoftware']\n",
      "['can', 'you', 'please', 'list', 'me', 'the', 'algorithms', 'for', 'instance', 'based', 'and', 'model', 'based']\n",
      "['can', 'we', 'just', 'use', 'while', 'loops', 'in', 'python', 'and', 'iterate', 'to', 'power', 'of', '2', 'and', 'get', 'an', 'output', 'list']\n",
      "['i', 'have', 'one', 'query', 'related', 'with', 'this', 'series', 'sir', 'is', 'this', 'crash', 'course', 'on', 'machine', 'learning', 'with', 'continue', 'till', 'algorithms', 'with', 'end', 'to', 'end', 'ml', 'projects', 'with', 'deployment', 'on', 'cloud', 'server', 'sir']\n",
      "['for', 'linear', 'points', 'we', 'can', 'find', 'the', 'values', 'of', 'm', 'and', 'c', 'using', 'given', 'two', 'points', 'by', 'substituting', 'in', 'y', 'mx', 'c', 'then', 'we', 'can', 'plot', 'as', 'many', 'points', 'as', 'we', 'need', 'for', 'different', 'x', 'values', 'as', 'we', 'know', 'the', 'equation', 'of', 'line', 'for', 'polynomial', 'also', 'we', 'can', 'take', 'the', 'same', 'approach', 'by', 'taking', 'a', 'quadratic', 'equation', 'y', 'mx2', 'c', 'here', 'we', 'subsitute', 'x2', 'and', 'y', 'of', 'given', 'points', 'and', 'find', 'the', 'm', 'and', 'c', 'now', 'we', 'will', 'have', 'the', 'equation', 'of', 'curve', 'we', 'can', 'plot', 'points', 'for', 'different', 'x', 'values']\n",
      "['sir', 'when', 'will', 'u', 'upload', 'videos', 'in', 'ml', 'end', 'to', 'end', 'series']\n",
      "['ig', 'we', 'have', 'to', 'use', 'linear', 'regression', 'model', 'for', 'the', 'particular', 'data', 'points']\n"
     ]
    }
   ],
   "source": [
    "######extracting text from comments#########\n",
    "\n",
    "def comment_text(text):\n",
    "    lem_words = []\n",
    "    new_list=[]\n",
    "\n",
    "    try:\n",
    "        ##changing text to lower_case##\n",
    "        text=text.lower()\n",
    "        ##removing tabs if any###\n",
    "        text=text.expandtabs(0)\n",
    "        ####removing punctuations\n",
    "        text=text.translate(str.maketrans('', '', string.punctuation))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    else:\n",
    "        ####splitting words of phrase/para\n",
    "        token_words = nltk.word_tokenize(text)\n",
    "        print(token_words)\n",
    "        \n",
    "    def remove_stop_words(token_words):\n",
    "        for words in token_words:\n",
    "            if words not in stop_words:\n",
    "                new_list.append(words)\n",
    "    remove_stop_words(token_words)\n",
    "    \n",
    "    def lemmatize_words(words_list):\n",
    "        lm= WordNetLemmatizer()\n",
    "        for word in words_list:\n",
    "            lem_words.append(lm.lemmatize(word))\n",
    "    lemmatize_words(new_list)\n",
    "    #print(lem_words)\n",
    "    \n",
    "for content in comments_extract:\n",
    "    comment_text(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_extract=[]\n",
    "def extract_text(doc):\n",
    "    for i in range(len(comment_list)):\n",
    "        comments_extract.append(comment_list[i])\n",
    "extract_text(comment_list)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
